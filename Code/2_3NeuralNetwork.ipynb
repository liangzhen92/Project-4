{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('data.pickle','rb') as read_file:\n",
    "    df = pickle.load(read_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "djia_data_2 = pd.read_csv('DIA_index.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "djia_data_2['Predicted'] = y_test_pre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "money = 2000\n",
    "prev = -1\n",
    "num_stock = 1\n",
    "\n",
    "for i in range(0, len(djia_data_2)): \n",
    "#     inital_stock = money / 17823\n",
    "    if djia_data_2.loc[i,'Predicted'] == prev:\n",
    "        continue\n",
    "    elif djia_data_2.loc[i,'Predicted'] != prev:\n",
    "        if djia_data_2.loc[i,'Predicted'] == 0:     \n",
    "            money = djia_data_2.loc[i,'Adj Close'] * num_stock\n",
    "            prev = djia_data_2.loc[i,'Predicted']         \n",
    "        if djia_data_2.loc[i,'Predicted'] == 1:\n",
    "            num_stock = money / djia_data_2.loc[i,'Adj Close']\n",
    "            prev = djia_data_2.loc[i,'Predicted']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3175.538803934068"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "money"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>lag1</th>\n",
       "      <th>lag2</th>\n",
       "      <th>lag3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.192015</td>\n",
       "      <td>-0.014492</td>\n",
       "      <td>0.069302</td>\n",
       "      <td>0.132442</td>\n",
       "      <td>0.003927</td>\n",
       "      <td>0.045849</td>\n",
       "      <td>-0.118786</td>\n",
       "      <td>0.082788</td>\n",
       "      <td>0.165037</td>\n",
       "      <td>0.095835</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.070369</td>\n",
       "      <td>-0.024457</td>\n",
       "      <td>0.033717</td>\n",
       "      <td>-0.192162</td>\n",
       "      <td>0.149033</td>\n",
       "      <td>0.084145</td>\n",
       "      <td>-0.024440</td>\n",
       "      <td>0.411624</td>\n",
       "      <td>-0.314850</td>\n",
       "      <td>-0.079474</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.000521</td>\n",
       "      <td>-0.098438</td>\n",
       "      <td>-0.106019</td>\n",
       "      <td>0.090017</td>\n",
       "      <td>-0.038098</td>\n",
       "      <td>0.356577</td>\n",
       "      <td>0.028341</td>\n",
       "      <td>0.321434</td>\n",
       "      <td>-0.049653</td>\n",
       "      <td>0.240879</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.063446</td>\n",
       "      <td>-0.118456</td>\n",
       "      <td>-0.081942</td>\n",
       "      <td>-0.014692</td>\n",
       "      <td>0.012867</td>\n",
       "      <td>-0.101457</td>\n",
       "      <td>-0.078922</td>\n",
       "      <td>-0.091120</td>\n",
       "      <td>0.087616</td>\n",
       "      <td>-0.085515</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.163115</td>\n",
       "      <td>-0.055939</td>\n",
       "      <td>-0.005450</td>\n",
       "      <td>-0.077413</td>\n",
       "      <td>-0.008766</td>\n",
       "      <td>0.045063</td>\n",
       "      <td>0.182410</td>\n",
       "      <td>0.178065</td>\n",
       "      <td>0.297217</td>\n",
       "      <td>0.070074</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6  \\\n",
       "0  0.192015 -0.014492  0.069302  0.132442  0.003927  0.045849 -0.118786   \n",
       "1  0.070369 -0.024457  0.033717 -0.192162  0.149033  0.084145 -0.024440   \n",
       "2 -0.000521 -0.098438 -0.106019  0.090017 -0.038098  0.356577  0.028341   \n",
       "3  0.063446 -0.118456 -0.081942 -0.014692  0.012867 -0.101457 -0.078922   \n",
       "4 -0.163115 -0.055939 -0.005450 -0.077413 -0.008766  0.045063  0.182410   \n",
       "\n",
       "          7         8         9  lag1  lag2  lag3  \n",
       "0  0.082788  0.165037  0.095835   1.0   1.0   0.0  \n",
       "1  0.411624 -0.314850 -0.079474   0.0   1.0   1.0  \n",
       "2  0.321434 -0.049653  0.240879   1.0   1.0   0.0  \n",
       "3 -0.091120  0.087616 -0.085515   1.0   0.0   0.0  \n",
       "4  0.178065  0.297217  0.070074   0.0   0.0   0.0  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "#######################\n",
    "# standard code block #\n",
    "#######################\n",
    "\n",
    "# see https://ipython.readthedocs.io/en/stable/interactive/magics.html\n",
    "%pylab inline\n",
    "\n",
    "# sets backend to render higher res images\n",
    "%config InlineBackend.figure_formats = ['retina']\n",
    "\n",
    "#######################\n",
    "#       imports       #\n",
    "#######################\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import sklearn\n",
    "\n",
    "sns.set_style(\"whitegrid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = df[df['Date'] < '2015-01-01']\n",
    "test = df[df['Date'] > '2014-12-31']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1611, 29726)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv = CountVectorizer(stop_words='english')\n",
    "\n",
    "X_fit = cv.fit(train['text'])\n",
    "X_transform = X_fit.transform(train['text'])\n",
    "X_test = X_fit.transform(test['text'])\n",
    "y_test = test['Label']\n",
    "df_train = pd.DataFrame(X_transform.toarray(), columns=cv.get_feature_names())\n",
    "df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "svd = TruncatedSVD(n_components=5, n_iter=100, random_state=42)\n",
    "svd_fit = svd.fit(X_transform)  \n",
    "svd_transform = svd_fit.transform(X_transform)\n",
    "svd_transform_test = svd_fit.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[10.0021102 ,  0.97925018,  0.63459904,  1.16009031,  0.08101788],\n",
       "       [ 8.92022479,  0.835194  ,  0.18123749, -3.05109767,  2.07960378],\n",
       "       [ 8.28974237, -0.23426188, -1.59900583,  0.60969081, -0.49779374],\n",
       "       ...,\n",
       "       [ 5.24672137, -0.65698395, -1.66507412, -1.26809021, -0.17169268],\n",
       "       [ 8.23596771,  0.5789071 ,  0.30872772,  0.17698137, -1.71190342],\n",
       "       [ 9.80173606, -0.13760622, -1.55747546,  0.66972657, -2.596881  ]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svd_transform_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[10.40851927,  4.28823476,  5.82880248, -0.44715637,  2.30657461],\n",
       "       [ 8.16196103,  5.05806067,  6.9437094 ,  3.20926063, -1.42774366],\n",
       "       [ 8.27953992,  4.99211138,  6.1630044 ,  3.97691677, -0.88806757],\n",
       "       ...,\n",
       "       [ 7.36870786,  1.89830138,  0.98665995, -0.59882602,  0.97432039],\n",
       "       [ 6.61860955,  1.52311707, -1.40105135, -2.26456217,  1.62324523],\n",
       "       [ 8.42087406,  1.76306941, -0.58732829,  5.37007707,  2.08130096]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svd_transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_svd = pd.DataFrame(svd_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_svd = pd.DataFrame(svd_transform_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalize data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('data_train.pickle','rb') as read_file:\n",
    "    df_train = pickle.load(read_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('data_train_y.pickle','rb') as read_file:\n",
    "    df_train_y = pickle.load(read_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('data_test.pickle','rb') as read_file:\n",
    "    df_test = pickle.load(read_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('data_test_y.pickle','rb') as read_file:\n",
    "    df_test_y = pickle.load(read_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.iloc[:,0:10] = (df_train.iloc[:,0:10] - df_train.iloc[:,0:10].mean()) / (df_train.iloc[:,0:10].max() - df_train.iloc[:,0:10].min())\n",
    "df_test.iloc[:,0:10] = (df_test.iloc[:,0:10] - df_test.iloc[:,0:10].mean()) / (df_test.iloc[:,0:10].max() - df_test.iloc[:,0:10].min())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "svd_transform = np.array(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "svd_transform_test = np.array(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.array(df_train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1611, 13)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svd_transform.shape\n",
    "# y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zhaoze/anaconda3/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:916: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.67486950\n",
      "Iteration 2, loss = 0.66693641\n",
      "Iteration 3, loss = 0.66656787\n",
      "Iteration 4, loss = 0.66784326\n",
      "Iteration 5, loss = 0.66743422\n",
      "Iteration 6, loss = 0.66536538\n",
      "Iteration 7, loss = 0.66592070\n",
      "Iteration 8, loss = 0.66472120\n",
      "Iteration 9, loss = 0.66458938\n",
      "Iteration 10, loss = 0.66269931\n",
      "Iteration 11, loss = 0.66541202\n",
      "Iteration 12, loss = 0.66361637\n",
      "Iteration 13, loss = 0.66409564\n",
      "Iteration 14, loss = 0.66480023\n",
      "Iteration 15, loss = 0.66316334\n",
      "Iteration 16, loss = 0.66450680\n",
      "Iteration 17, loss = 0.66230398\n",
      "Iteration 18, loss = 0.66399555\n",
      "Iteration 19, loss = 0.66365219\n",
      "Iteration 20, loss = 0.66302868\n",
      "Iteration 21, loss = 0.66440596\n",
      "Iteration 22, loss = 0.66421506\n",
      "Iteration 23, loss = 0.66261625\n",
      "Iteration 24, loss = 0.66293611\n",
      "Iteration 25, loss = 0.66359773\n",
      "Iteration 26, loss = 0.66189281\n",
      "Iteration 27, loss = 0.66449242\n",
      "Iteration 28, loss = 0.66341508\n",
      "Iteration 29, loss = 0.66268862\n",
      "Iteration 30, loss = 0.66327736\n",
      "Iteration 31, loss = 0.66111965\n",
      "Iteration 32, loss = 0.66246199\n",
      "Iteration 33, loss = 0.66310088\n",
      "Iteration 34, loss = 0.66205251\n",
      "Iteration 35, loss = 0.66202630\n",
      "Iteration 36, loss = 0.66244026\n",
      "Iteration 37, loss = 0.66238193\n",
      "Iteration 38, loss = 0.66266949\n",
      "Iteration 39, loss = 0.66217131\n",
      "Iteration 40, loss = 0.66227421\n",
      "Iteration 41, loss = 0.66195490\n",
      "Iteration 42, loss = 0.66240447\n",
      "Training loss did not improve more than tol=0.000000 for 10 consecutive epochs. Stopping.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='tanh', alpha=0.0001, batch_size=3, beta_1=0.9,\n",
       "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "       hidden_layer_sizes=(100, 100, 100), learning_rate='constant',\n",
       "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
       "       n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
       "       random_state=42, shuffle=True, solver='sgd', tol=1e-09,\n",
       "       validation_fraction=0.1, verbose=10, warm_start=False)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "# X = [[0., 0.], [1., 1.]]\n",
    "# y = [0, 1]\n",
    "clf = MLPClassifier(solver='sgd', alpha=0.0001, activation = 'tanh',batch_size = 3,\n",
    "                     hidden_layer_sizes=(100, 100, 100),  verbose=10,  tol=0.000000001, random_state=42)\n",
    "\n",
    "clf.fit(svd_transform, y) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pre = clf.predict(svd_transform_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1,\n",
       "       1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "       0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1,\n",
       "       0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1,\n",
       "       0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1,\n",
       "       1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1,\n",
       "       1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1,\n",
       "       0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1,\n",
       "       1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0,\n",
       "       1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0,\n",
       "       0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1,\n",
       "       1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1,\n",
       "       1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1,\n",
       "       1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1,\n",
       "       1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1,\n",
       "       1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1,\n",
       "       1, 1, 1, 1])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_pre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>95</td>\n",
       "      <td>91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>74</td>\n",
       "      <td>118</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted   0    1\n",
       "Actual            \n",
       "0          95   91\n",
       "1          74  118"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.crosstab(df_test_y, y_test_pre, colnames=[\"Predicted\"], rownames=[\"Actual\"] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction Accuracy is 56%!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn import kernel_approximation\n",
    "# import keras\n",
    "# from keras.layers import Activation, Dense\n",
    "\n",
    "# N_COMP = 10\n",
    "\n",
    "# x = df_norm.values\n",
    "\n",
    "# kernel_approx = kernel_approximation.Nystroem(n_components=N_COMP, gamma=2)\n",
    "\n",
    "# x_rbf_pre = kernel_approx.fit(x)\n",
    "# x_rbf = x_rbf_pre.transform(x)\n",
    "\n",
    "# # svm_keras = keras.Sequential([keras.layers.Dense(units=3, input_shape=(N_COMP, )), keras.layers.Dense(units=1,activation='tanh')])\n",
    "\n",
    "# keras.initializers.glorot_uniform(seed=None)\n",
    "# svm_keras = keras.Sequential()\n",
    "\n",
    "# svm_keras.add(Dense(output_dim=500, input_shape=(N_COMP, )))\n",
    "# svm_keras.add(Activation(\"relu\"))\n",
    "# svm_keras.add(Dense(output_dim=1))\n",
    "# svm_keras.add(Activation(\"tanh\"))\n",
    "\n",
    "# # model = keras.Sequential([\n",
    "# #     keras.layers.Flatten(input_shape=(28, 28)),\n",
    "# #     keras.layers.Dense(128, activation=tf.nn.relu),\n",
    "# #     keras.layers.Dense(10, activation=tf.nn.softmax)\n",
    "# # ])\n",
    "\n",
    "# # svm_keras = keras.Sequential(\n",
    "# #     [keras.layers.Dense(units=50, activation='relu', input_shape=(N_COMP, )),\n",
    "# #      keras.layers.Dense(units=30, activation='relu'),\n",
    "# #     keras.layers.Dense(units=1,activation='tanh')])\n",
    "\n",
    "# svm_keras.compile(optimizer=\"sgd\", loss=\"categorical_hinge\")\n",
    "\n",
    "# svm_keras_fit = svm_keras.fit(x=x_rbf, y=train[\"Label\"], batch_size= 5 , epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_test_cv = X_fit.transform(test['text'])\n",
    "# X_test_svd = svd_fit.transform(X_test_cv)\n",
    "# df_test_svd = pd.DataFrame(X_test_svd)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
